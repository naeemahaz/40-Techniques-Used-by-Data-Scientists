{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install textblob\n!pip install Distance\n!pip install zipfile36\nimport datetime\nimport seaborn as sns\nimport spacy\nfrom nltk import trigrams\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n#from keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom sklearn import metrics\n#from textblob_de import TextBlobDE as TextBlob\nfrom spacy.tokenizer import Tokenizer\nfrom spacy.lang.en import English\nimport en_core_web_lg\nnlp = spacy.blank(\"en\")\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd \nimport numpy as np \nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\nnltk.download('punkt')\nnltk.download('wordnet') \nnltk.download('omw-1.4')\nstopnow = set(stopwords.words(\"english\"))\nfrom nltk.tokenize import word_tokenize\nimport gensim\nfrom textblob import TextBlob\nfrom textblob import Word\nfrom sklearn.preprocessing import LabelEncoder\npd.set_option('display.max_columns', None)  \npd.set_option('display.max_rows', None)\nfrom string import punctuation\nfrom spacy.matcher import Matcher\nfrom spacy import displacy\nfrom gensim.models import Word2Vec\n#import en_core_web_sm\n#nlp = en_core_web_sm.load()\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import OrdinalEncoder\nimport scipy\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport time \n#import turicreate as tc \nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nfrom nltk import ngrams\nimport pandas as pd\nfrom collections import Counter\nfrom itertools import chain\nimport warnings\nwarnings.filterwarnings('ignore')\nnltk.download('averaged_perceptron_tagger')\nfrom numpy import array\n\n!pip install dedupe\n!pip install fuzzymatcher\n!pip install values\n!pip install similarity\n!pip install jarowinkler\n!pip install strsim\n!pip install pyjarowinkler\n!pip install Levenshtein\n!pip install strsimpy\n!pip install weighted-levenshtein\n!pip install recordlinkage\n!pip install keras-visualizer\n!pip install tfidf-matcher\n!pip install textdistance\n!pip install Distance\n!python3 -m pip install tabulate\n!pip install textblob\n\nfrom textblob import TextBlob\nfrom nltk.tokenize import TabTokenizer\nfrom textblob import Word\nimport tabulate\nfrom gensim.test.utils import common_texts, get_tmpfile\nfrom gensim.models import Word2Vec\nimport string\nimport values\nfrom similarity.jarowinkler import JaroWinkler\n#from similarity.levenshtein import Levenshtein\nfrom similarity.normalized_levenshtein import NormalizedLevenshtein\nfrom similarity.weighted_levenshtein import WeightedLevenshtein\nfrom similarity.weighted_levenshtein import CharacterSubstitutionInterface\nfrom similarity.damerau import Damerau\nfrom similarity.optimal_string_alignment import OptimalStringAlignment\nfrom similarity.longest_common_subsequence import LongestCommonSubsequence\nfrom similarity.metric_lcs import MetricLCS\nfrom similarity.ngram import NGram\nfrom similarity.qgram import QGram\nfrom similarity.cosine import Cosine\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom keras_visualizer import visualizer\nimport sklearn\nimport tfidf_matcher\nfrom strsimpy.jaro_winkler import JaroWinkler\nfrom strsimpy.damerau import Damerau\nfrom strsimpy.normalized_levenshtein import NormalizedLevenshtein\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport textdistance\nimport distance\nfrom gensim.models import Word2Vec\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process\nfrom difflib import SequenceMatcher\nimport sys, types, os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport matplotlib\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.util import ngrams\nfrom gensim.models import Word2Vec\nimport collections\nfrom collections import Counter\nfrom matplotlib import pyplot as plt\nstop = stopwords.words('english')\npd.options.mode.chained_assignment = None\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom spacy.matcher import Matcher\nimport spacy\nfrom spacy import displacy\nfrom gensim.models import Word2Vec\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline \nimport nltk\nimport gzip\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport heapq\nfrom wordcloud import WordCloud\nimport PIL\nimport itertools\nimport matplotlib.pyplot as plt\nfrom nltk import corpus\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect=CountVectorizer()\nimport scipy\nimport math\nimport os\nimport sklearn\nfrom itertools import islice\n\nfrom nltk import word_tokenize, pos_tag, ne_chunk\nfrom nltk import RegexpParser\nfrom nltk import Tree\nNP = \"NP: {(<V\\w+>|<NN\\w?>)+.*<NN\\w?>}\"\nchunker = RegexpParser(NP)\nfrom nltk import trigrams\nimport textdistance\n\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\nnltk.download('punkt')\nnltk.download('wordnet')\npd.set_option('display.width', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 1000)\n%matplotlib inline\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:28:01.346610Z","iopub.execute_input":"2022-06-20T00:28:01.347021Z","iopub.status.idle":"2022-06-20T00:31:19.212628Z","shell.execute_reply.started":"2022-06-20T00:28:01.346899Z","shell.execute_reply":"2022-06-20T00:31:19.211718Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: textblob in /opt/conda/lib/python3.7/site-packages (0.15.3)\nRequirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textblob) (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting Distance\n  Downloading Distance-0.1.3.tar.gz (180 kB)\n\u001b[K     |████████████████████████████████| 180 kB 2.2 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: Distance\n  Building wheel for Distance (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Distance: filename=Distance-0.1.3-py3-none-any.whl size=16275 sha256=ec2660db6c500a7d0b8627a493459b7b1032d45c0a7a8faba5407c11825a4406\n  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\nSuccessfully built Distance\nInstalling collected packages: Distance\nSuccessfully installed Distance-0.1.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/omw-1.4.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\nCollecting dedupe\n  Downloading dedupe-2.0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103 kB)\n\u001b[K     |████████████████████████████████| 103 kB 3.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.7/site-packages (from dedupe) (1.19.5)\nCollecting simplecosine>=1.2\n  Downloading simplecosine-1.2-py2.py3-none-any.whl (3.2 kB)\nCollecting affinegap>=1.3\n  Downloading affinegap-1.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (55 kB)\n\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s  eta 0:00:01\n\u001b[?25hCollecting BTrees>=4.1.4\n  Downloading BTrees-4.10.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.6 MB)\n\u001b[K     |████████████████████████████████| 3.6 MB 12.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from dedupe) (3.7.4.3)\nCollecting highered>=0.2.0\n  Downloading highered-0.2.1-py2.py3-none-any.whl (3.3 kB)\nCollecting Levenshtein-search==1.4.5\n  Downloading Levenshtein_search-1.4.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (71 kB)\n\u001b[K     |████████████████████████████████| 71 kB 5.8 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from dedupe) (0.23.2)\nRequirement already satisfied: haversine>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from dedupe) (2.5.1)\nCollecting zope.index\n  Downloading zope.index-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (105 kB)\n\u001b[K     |████████████████████████████████| 105 kB 60.4 MB/s eta 0:00:01\n\u001b[?25hCollecting dedupe-variable-datetime\n  Downloading dedupe_variable_datetime-0.1.5-py3-none-any.whl (4.8 kB)\nCollecting categorical-distance>=1.9\n  Downloading categorical_distance-1.9-py3-none-any.whl (3.3 kB)\nCollecting doublemetaphone\n  Downloading DoubleMetaphone-1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (150 kB)\n\u001b[K     |████████████████████████████████| 150 kB 63.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: zope.interface>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from BTrees>=4.1.4->dedupe) (5.4.0)\nCollecting persistent>=4.1.0\n  Downloading persistent-4.9.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n\u001b[K     |████████████████████████████████| 253 kB 70.9 MB/s eta 0:00:01\n\u001b[?25hCollecting pyhacrf-datamade>=0.2.0\n  Downloading pyhacrf_datamade-0.2.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (972 kB)\n\u001b[K     |████████████████████████████████| 972 kB 51.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from persistent>=4.1.0->BTrees>=4.1.4->dedupe) (1.14.6)\nCollecting PyLBFGS>=0.1.3\n  Downloading PyLBFGS-0.2.0.14-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (239 kB)\n\u001b[K     |████████████████████████████████| 239 kB 47.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from zope.interface>=5.0.0->BTrees>=4.1.4->dedupe) (57.4.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->persistent>=4.1.0->BTrees>=4.1.4->dedupe) (2.20)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from dedupe-variable-datetime->dedupe) (0.18.2)\nCollecting datetime-distance\n  Downloading datetime_distance-0.1.3-py3-none-any.whl (4.1 kB)\nRequirement already satisfied: python-dateutil>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from datetime-distance->dedupe-variable-datetime->dedupe) (2.8.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.0->datetime-distance->dedupe-variable-datetime->dedupe) (1.15.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dedupe) (2.2.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dedupe) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->dedupe) (1.7.1)\nInstalling collected packages: PyLBFGS, persistent, pyhacrf-datamade, datetime-distance, BTrees, zope.index, simplecosine, Levenshtein-search, highered, doublemetaphone, dedupe-variable-datetime, categorical-distance, affinegap, dedupe\nSuccessfully installed BTrees-4.10.0 Levenshtein-search-1.4.5 PyLBFGS-0.2.0.14 affinegap-1.12 categorical-distance-1.9 datetime-distance-0.1.3 dedupe-2.0.16 dedupe-variable-datetime-0.1.5 doublemetaphone-1.1 highered-0.2.1 persistent-4.9.0 pyhacrf-datamade-0.2.6 simplecosine-1.2 zope.index-5.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting fuzzymatcher\n  Downloading fuzzymatcher-0.0.6-py3-none-any.whl (15 kB)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from fuzzymatcher) (2.8.0)\nCollecting metaphone\n  Downloading Metaphone-0.6.tar.gz (14 kB)\nRequirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.7/site-packages (from fuzzymatcher) (0.12.2)\nCollecting rapidfuzz\n  Downloading rapidfuzz-2.0.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[K     |████████████████████████████████| 1.8 MB 3.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fuzzymatcher) (1.3.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fuzzymatcher) (1.19.5)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fuzzymatcher) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->fuzzymatcher) (1.15.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from python-Levenshtein->fuzzymatcher) (57.4.0)\nCollecting jarowinkler<1.1.0,>=1.0.2\n  Downloading jarowinkler-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103 kB)\n\u001b[K     |████████████████████████████████| 103 kB 61.3 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: metaphone\n  Building wheel for metaphone (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13919 sha256=1b431651d445ac397adb363b6e0dee65d72106e8d563f1e3c0f26dc2d540d670\n  Stored in directory: /root/.cache/pip/wheels/1d/a8/cb/6f8902aa5457bd71344e00665c230e9c45255b3f57f2194a0f\nSuccessfully built metaphone\nInstalling collected packages: jarowinkler, rapidfuzz, metaphone, fuzzymatcher\nSuccessfully installed fuzzymatcher-0.0.6 jarowinkler-1.0.2 metaphone-0.6 rapidfuzz-2.0.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting values\n  Downloading values-2020.12.3.tar.gz (1.3 kB)\nBuilding wheels for collected packages: values\n  Building wheel for values (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for values: filename=values-2020.12.3-py3-none-any.whl size=1385 sha256=8018bb126730f998c6f0eb8c0828a0a35cdb93e546dd8e97bd2ea9b7b09bbe42\n  Stored in directory: /root/.cache/pip/wheels/72/5b/76/a2fdac16138610fb0433ad75827f79def289083d657f2d394e\nSuccessfully built values\nInstalling collected packages: values\nSuccessfully installed values-2020.12.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting similarity\n  Downloading similarity-0.0.1-py3-none-any.whl (8.3 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from similarity) (1.19.5)\nCollecting editdistance\n  Downloading editdistance-0.6.0-cp37-cp37m-manylinux2010_x86_64.whl (285 kB)\n\u001b[K     |████████████████████████████████| 285 kB 2.3 MB/s eta 0:00:01\n\u001b[?25hCollecting interaction\n  Downloading interaction-1.3-py3-none-any.whl (7.2 kB)\nCollecting jellyfish\n  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n\u001b[K     |████████████████████████████████| 132 kB 44.1 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: jellyfish\n  Building wheel for jellyfish (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=92072 sha256=0acf20f4392eed8fcd5446f26d9b43004ee35c5b4d88a0a20bfbad69312e47f9\n  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\nSuccessfully built jellyfish\nInstalling collected packages: jellyfish, interaction, editdistance, similarity\nSuccessfully installed editdistance-0.6.0 interaction-1.3 jellyfish-0.9.0 similarity-0.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: jarowinkler in /opt/conda/lib/python3.7/site-packages (1.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting strsim\n  Downloading strsim-0.0.3-py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 296 kB/s eta 0:00:011\n\u001b[?25hInstalling collected packages: strsim\nSuccessfully installed strsim-0.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting pyjarowinkler\n  Downloading pyjarowinkler-1.8-py2.py3-none-any.whl (5.9 kB)\nInstalling collected packages: pyjarowinkler\nSuccessfully installed pyjarowinkler-1.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting Levenshtein\n  Downloading Levenshtein-0.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (258 kB)\n\u001b[K     |████████████████████████████████| 258 kB 2.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: rapidfuzz<3.0.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from Levenshtein) (2.0.11)\nRequirement already satisfied: jarowinkler<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from rapidfuzz<3.0.0,>=2.0.1->Levenshtein) (1.0.2)\nInstalling collected packages: Levenshtein\nSuccessfully installed Levenshtein-0.18.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting strsimpy\n  Downloading strsimpy-0.2.1-py3-none-any.whl (45 kB)\n\u001b[K     |████████████████████████████████| 45 kB 890 kB/s eta 0:00:011\n\u001b[?25hInstalling collected packages: strsimpy\nSuccessfully installed strsimpy-0.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting weighted-levenshtein\n  Downloading weighted_levenshtein-0.2.1.tar.gz (129 kB)\n\u001b[K     |████████████████████████████████| 129 kB 2.2 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: weighted-levenshtein\n  Building wheel for weighted-levenshtein (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for weighted-levenshtein: filename=weighted_levenshtein-0.2.1-cp37-cp37m-linux_x86_64.whl size=334849 sha256=8ef9026fa5b9f332ef11ee9fdfc30ebd060cb4711624ebc8c4ded3bced1c9a90\n  Stored in directory: /root/.cache/pip/wheels/a1/cd/2e/d1ef8a9e61c14e20842ff10c98eae98a64610ef18bc5fff8fa\nSuccessfully built weighted-levenshtein\nInstalling collected packages: weighted-levenshtein\nSuccessfully installed weighted-levenshtein-0.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting recordlinkage\n  Downloading recordlinkage-0.15-py3-none-any.whl (926 kB)\n\u001b[K     |████████████████████████████████| 926 kB 2.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (1.0.1)\nRequirement already satisfied: jellyfish>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (0.9.0)\nRequirement already satisfied: numpy>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (1.19.5)\nRequirement already satisfied: scikit-learn>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (0.23.2)\nRequirement already satisfied: scipy>=1 in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (1.7.1)\nRequirement already satisfied: pandas<2,>=1 in /opt/conda/lib/python3.7/site-packages (from recordlinkage) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2,>=1->recordlinkage) (2.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2,>=1->recordlinkage) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2,>=1->recordlinkage) (1.15.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.0->recordlinkage) (2.2.0)\nInstalling collected packages: recordlinkage\nSuccessfully installed recordlinkage-0.15\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting keras-visualizer\n  Downloading keras_visualizer-2.4-py3-none-any.whl (5.4 kB)\nInstalling collected packages: keras-visualizer\nSuccessfully installed keras-visualizer-2.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting tfidf-matcher\n  Downloading tfidf_matcher-0.2.1-py2.py3-none-any.whl (7.8 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from tfidf-matcher) (1.3.2)\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from tfidf-matcher) (0.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->tfidf-matcher) (1.19.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->tfidf-matcher) (2.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->tfidf-matcher) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->tfidf-matcher) (1.15.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn->tfidf-matcher) (0.23.2)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->tfidf-matcher) (1.7.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->tfidf-matcher) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->tfidf-matcher) (2.2.0)\nInstalling collected packages: tfidf-matcher\nSuccessfully installed tfidf-matcher-0.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting textdistance\n  Downloading textdistance-4.2.2-py3-none-any.whl (28 kB)\nInstalling collected packages: textdistance\nSuccessfully installed textdistance-4.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: Distance in /opt/conda/lib/python3.7/site-packages (0.1.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (0.8.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: textblob in /opt/conda/lib/python3.7/site-packages (0.15.3)\nRequirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textblob) (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"articles = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv')   \ncustomer = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/customers.csv')  \ntrain = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/transactions_train.csv')\nsample = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:31:33.425306Z","iopub.execute_input":"2022-06-20T00:31:33.425620Z","iopub.status.idle":"2022-06-20T00:32:53.222445Z","shell.execute_reply.started":"2022-06-20T00:31:33.425585Z","shell.execute_reply":"2022-06-20T00:32:53.220752Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"articles = articles.dropna()\ncustomer = customer.dropna()\ntrain = train.dropna()\nsample = sample.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:32:53.226088Z","iopub.execute_input":"2022-06-20T00:32:53.226867Z","iopub.status.idle":"2022-06-20T00:33:03.911094Z","shell.execute_reply.started":"2022-06-20T00:32:53.226824Z","shell.execute_reply":"2022-06-20T00:33:03.910198Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cust_sample = sample[['customer_id']]\ntrain_sample = pd.merge(cust_sample, train,on= 'customer_id', how='left')\ntrain_sam_cust = pd.merge(train_sample, customer, on='customer_id', how='left')\ntrain_sam_cust = train_sam_cust[['t_dat','customer_id','article_id','price','Active','club_member_status','fashion_news_frequency']]\ntrain_sam_cust = train_sam_cust.sample(900000)\ntrain_sam_cust_art = pd.merge(train_sam_cust, articles, on='article_id', how='inner')","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:33:42.596708Z","iopub.execute_input":"2022-06-20T00:33:42.597775Z","iopub.status.idle":"2022-06-20T00:34:30.499843Z","shell.execute_reply.started":"2022-06-20T00:33:42.597730Z","shell.execute_reply":"2022-06-20T00:34:30.498547Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"datause = train_sam_cust_art.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:34:30.502149Z","iopub.execute_input":"2022-06-20T00:34:30.502541Z","iopub.status.idle":"2022-06-20T00:34:31.369647Z","shell.execute_reply.started":"2022-06-20T00:34:30.502489Z","shell.execute_reply":"2022-06-20T00:34:31.368789Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datause['Active'] = datause['Active'].fillna(0)\ndatause['Active'] = datause['Active'].astype(np.int64)\ndatause['fashion_news_frequency'] = datause['fashion_news_frequency'].fillna('NONE')\ndatause['club_member_status'] = datause['club_member_status'].fillna('NONE')\ndatause.product_code = datause.product_code.astype(str)\ndatause.price = datause.price.astype(str)\ndatause.article_id = datause.article_id.astype(str)\ndatause['words'] = datause['product_group_name'] +\" \"+ datause['graphical_appearance_name'] +\" \"+ datause['colour_group_name'] +\" \"+ datause['perceived_colour_value_name']+\" \"+ datause['perceived_colour_master_name'] +\" \"+ datause['department_name'] +\" \"+ datause['index_name'] +\" \"+ datause['index_group_name']+\" \"+ datause['section_name']+\" \"+ datause['garment_group_name']+\" \"+ datause['detail_desc']\ndatause.words = datause.words.astype(str)\ndatause['words'] = datause['words'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['words'] = datause['words'].str.replace('[^\\w\\s]','')\ndatause['words'] = datause['words'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopnow))\ndatause['words'] = datause['words'].str.replace('\\d+', '')\ndatause['words'] = datause['words'].str.split().apply(lambda x: ' '.join(list(set(x))))\ndatause['token_words']  = datause.apply(lambda row: nltk.word_tokenize(row['words']), axis=1)\ndatause.token_words = datause.token_words.astype(str)\ndatause['lemma_words'] = datause.token_words.apply(lemmatize_text)\n\n\n\n#datause['words'] = datause['words'].astype(str)\ndatause['product_type_name'] = datause['product_type_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['index_name'] = datause['index_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['prod_name'] = datause['prod_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['product_type_name'] = datause['product_type_name'].str.replace('[^\\w\\s]','')\ndatause['index_name'] = datause['index_name'].str.replace('[^\\w\\s]','')\ndatause['prod_name'] = datause['prod_name'].str.replace('[^\\w\\s]','')\n\ndatause['tag'] = datause['article_id'] +\" \"+ datause['product_code'] +\" \"+ datause['product_type_name'] +\" \"+ datause['index_name']+\" \"+ datause['prod_name']+\" \"+ datause['perceived_colour_value_name']+\" \"+ datause['product_group_name']\ndatause.tag = datause.tag.astype(str)\ndatause['tag'] = datause['tag'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['tag'] = datause['tag'].str.replace('[^\\w\\s]','')\ndatause['token_tag']  = datause.apply(lambda row: nltk.word_tokenize(row['tag']), axis=1)\ndatause.token_tag = datause.token_tag.astype(str)\ndatause['lemma_tag'] = datause.token_tag.apply(lemmatize_text)\n\ndatause = datause.dropna()\n\n##datause['tag'] = datause['product_code'] +\" - \"+ datause['product_type_name'] \n##datause['tag'] = datause['product_type_name'] \n##datause['tag'] = datause['tag'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n##datause = datause.dropna()\n##datause = datause.reset_index(drop=True)\n##datause['words_token'] = datause.words.apply(lambda x: word_tokenize(x))\n##datause['words_lemma'] = datause['words'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))","metadata":{"execution":{"iopub.status.busy":"2022-06-20T00:34:43.895548Z","iopub.execute_input":"2022-06-20T00:34:43.895864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datause[['t_dat',\n 'customer_id',\n 'article_id',\n 'price',\n 'Active',\n 'club_member_status',\n 'fashion_news_frequency','token_words','lemma_words','token_tag','lemma_tag']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n#tokens = []\n#lemma = []\n#pos = []\n#ep = []\n\n\n\n#for doc in nlp.pipe(dataset['words'].astype('unicode').values, batch_size=100,\n#                       n_process=10):\n #   if doc.is_parsed:\n  #      tokens.append([n.text for n in doc])\n  #      lemma.append([n.lemma_ for n in doc])\n  #      #pos.append([n.pos_ for n in doc])\n        #dep.append([n.dep_ for n in doc])\n        \n        \n        \n #   else:\n        # We want to make sure that the lists of parsed results have the\n        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n   #     tokens.append(None)\n   #     lemma.append(None)\n        #pos.append(None)\n        #dep.append(None)\n        \n        \n        \n\n#dataset['tokens_words'] = tokens\n#dataset['lemma_words'] = lemma\n#dataset['pos_words'] = pos\n#dataset['dep_words'] = dep","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n#tokens = []\n#lemma = []\n#pos = []\n#dep = []\n\n\n\n#for doc in nlp.pipe(dataset['tag'].astype('unicode').values, batch_size=100,\n #                       n_process=10):\n  #  if doc.is_parsed:\n  #     tokens.append([n.text for n in doc])\n  #      lemma.append([n.lemma_ for n in doc])\n #       #pos.append([n.pos_ for n in doc])\n        #dep.append([n.dep_ for n in doc])\n        \n        \n        \n #   else:\n        # We want to make sure that the lists of parsed results have the\n        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n   #     tokens.append(None)\n   #     lemma.append(None)\n        #pos.append(None)\n        #dep.append(None)\n        \n        \n        \n\n#dataset['tokens_tag'] = tokens\n#dataset['lemma_tag'] = lemma\n#dataset['pos_tag'] = pos\n#dataset['dep_tag'] = dep","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = dataset[['t_dat',\n 'customer_id','price','Active',\n 'club_member_status',\n 'fashion_news_frequency',\n 'lemma_tag','lemma_words']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = features[['lemma_tag']] \nfeatures = features.drop('lemma_tag',1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target['lemma_words'] = target['lemma_tag']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"features.to_csv (r'C:\\Users\\Naeemah\\Desktop\\org_features.csv', index = False, header=True)\ntarget.to_csv (r'C:\\Users\\Naeemah\\Desktop\\org_target.csv', index = False, header=True)","metadata":{}},{"cell_type":"code","source":"#import fuzzymatcher\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['lemma_words'] = features['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"left_on = [\"lemma_words\"]","metadata":{}},{"cell_type":"code","source":"target['lemma_words'] = target['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"right_on = [\"lemma_words\"]","metadata":{}},{"cell_type":"markdown","source":"matched_results = fuzzymatcher.fuzzy_left_join(features,\n                                            target,\n                                            left_on,\n                                            right_on,\n                                            left_id_col='lemma_words',\n                                            right_id_col='lemma_words')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:13:20.906709Z","iopub.execute_input":"2022-03-25T08:13:20.907117Z"}}},{"cell_type":"markdown","source":"%%time\nfrom recordlinkage.standardise import value_occurence\nfeatures[\"product_info\"] = value_occurence(features[\"lemma_words\"])","metadata":{}},{"cell_type":"code","source":"#features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresnew = features[features[\"product_info\"] >= 15]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"%%time\njarowinkler = JaroWinkler()\nfeatures[\"jarowinkler_sim\"] = [jarowinkler.similarity(i,j) for i,j in zip(features['lemma_words'],target['lemma_words'])]","metadata":{}},{"cell_type":"code","source":"#features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.sample(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['price'] = features['price'].astype(str)\nfeatures['Active'] = features['Active'].astype(str)\n#features['product_info'] = features['product_info'].astype(str)\n#features['jarowinkler_sim'] = features['jarowinkler_sim'].astype(str)\ntarget['lemma_tag'] = target['lemma_tag'].astype(str)\ntarget['lemma_words'] = target['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"left_on = [\"t_dat\",\n \"customer_id\",\n \"price\",\n \"Active\",\n \"club_member_status\",\n \"fashion_news_frequency\",\n \"lemma_words\",\n \"product_info\",\n \"jarowinkler_sim\"]","metadata":{}},{"cell_type":"markdown","source":"right_on = [\"lemma_tag\",\"lemma_words\"]","metadata":{}},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['lemma_words'] = features['lemma_words'].str.replace(\"[\\[\\]\\\"']\", \"\")\nfeatures['lemma_words'] = features['lemma_words'].str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"swords = []\n\nfor ind in features.index:\n    swords = features['lemma_words'][ind]\n    syn = list()\n    \nfor synset in wn.synsets(swords):\n    for lemma in synset.lemmas():\n        syn.append(lemma.name())\n\ndf = pd.DataFrame(syn,swords=['synonyms' + swords])\nprint(\"syn\" + swords + str(syn))\nswords.append(syn)\nfeatures = features.assign(newcol = columns)\n    \n    \n    \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"%%time\nimport recordlinkage\n\nindexer = recordlinkage.Index()\n# Create indexing object\nindexer = recordlinkage.SortedNeighbourhoodIndex(on='lemma_words', window=9)\n\n# Create pandas MultiIndex containing candidate links\ncandidate_links = indexer.index(features, target)\ncomp = recordlinkage.Compare()\ncomp.string('lemma_words', 'lemma_words', method='jarowinkler', label='words')\nmymatches = comp.compute(candidate_links, features, target)\nprint(mymatches)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:35.795038Z","iopub.execute_input":"2022-04-05T22:45:35.795348Z","iopub.status.idle":"2022-04-05T22:45:42.335944Z","shell.execute_reply.started":"2022-04-05T22:45:35.79531Z","shell.execute_reply":"2022-04-05T22:45:42.335188Z"}}},{"cell_type":"markdown","source":"mymatches","metadata":{}},{"cell_type":"markdown","source":"t =mymatches.sum(axis=1).value_counts().sort_index(ascending=False)\nprint(t)","metadata":{}},{"cell_type":"markdown","source":"#potential_matches = mymatches[mymatches].reset_index()\n#potential_matches['Score'] = potential_matches.loc[:,'words']\n\npotential_matches = mymatches[mymatches.sum(axis=1) < 1].reset_index()\npotential_matches['Score'] = potential_matches.loc[:,'words']\n","metadata":{}},{"cell_type":"markdown","source":"potential_matches.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:42.37937Z","iopub.execute_input":"2022-04-05T22:45:42.379641Z","iopub.status.idle":"2022-04-05T22:45:42.393797Z","shell.execute_reply.started":"2022-04-05T22:45:42.379605Z","shell.execute_reply":"2022-04-05T22:45:42.393053Z"}}},{"cell_type":"markdown","source":"potential_matches.dtypes","metadata":{}},{"cell_type":"markdown","source":"from tabulate import tabulate\nprint(tabulate(potential_matches,headers =[\"Recordid_1\",\"Recordid_2\",\"words\", \"Score\" ]))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:42.406558Z","iopub.execute_input":"2022-04-05T22:45:42.407034Z","iopub.status.idle":"2022-04-05T22:45:42.421611Z","shell.execute_reply.started":"2022-04-05T22:45:42.406993Z","shell.execute_reply":"2022-04-05T22:45:42.42083Z"}}},{"cell_type":"code","source":"#potential_matches['level_1']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['Features_Lookup'] = features[['lemma_words']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target['Target_Lookup'] =  target[['lemma_words']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target.to_csv ('finaltarget.csv', index = False, header=True)\n#features.to_csv ('finalfeatures.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup = features[['Features_Lookup','t_dat','customer_id','price','Active','club_member_status','fashion_news_frequency']].reset_index()\ntar_lookup = target[['Target_Lookup','lemma_words']].reset_index()\n#print(feat_lookup)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tar_lookup.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tar_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = tar_lookup[['Target_Lookup']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['target_label'] = targetfinal['Target_Lookup'].str.replace(\"[\\[\\]\\\"']\", \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['target_label'] = targetfinal['target_label'] .str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = targetfinal[['target_label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup['features_label'] = feat_lookup['Features_Lookup'].str.replace(\"[\\[\\]\\\"']\", \"\")\nfeat_lookup['features_label'] = feat_lookup['features_label'] .str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal = feat_lookup[['customer_id','features_label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['article'] = targetfinal['target_label'].str[:9]\ntargetfinal['target_label'] = targetfinal['target_label'].str[15:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eft_on = [\"customer_id\",\"features_label\"]\n#right_on = [\"article\",\"target_label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"matched_results = fuzzymatcher.fuzzy_left_join(featuresfinal,\n                                            targetfinal,\n                                            left_on,\n                                            right_on,\n                                            left_id_col='features_label',\n                                            right_id_col='target_label')","metadata":{}},{"cell_type":"code","source":"def get_adjectives(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"JJ\"]\n\ntargetfinal['adjectives'] = targetfinal['target_label'].apply(get_adjectives)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_verbs(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"VB\"]\n\ntargetfinal['verbs'] = targetfinal['target_label'].apply(get_verbs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nouns(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"NN\"]\n\ntargetfinal['nouns'] = targetfinal['target_label'].apply(get_nouns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targetfinal['label'] = targetfinal['adjectives'] +\" \"+ targetfinal['nouns']\ntargetfinal.adjectives = targetfinal.adjectives.astype(str)\ntargetfinal.nouns = targetfinal.nouns.astype(str)\ntargetfinal['label'] = targetfinal['adjectives'] +\" \"+ targetfinal['nouns']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = targetfinal[['article','label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['label'] = targetfinal['label'].str.replace(\"[\\[\\]\\\"']\", \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal['label'] = featuresfinal['features_label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nimport recordlinkage\nindexer = recordlinkage.Index()\nindexer = recordlinkage.SortedNeighbourhoodIndex(on='label', window=9)\ncandidate_links = indexer.index(featuresfinal, targetfinal) \ncomp = recordlinkage.Compare() \ncomp.string('label', 'label', method='jarowinkler', label='labels') \nmymatches = comp.compute(candidate_links, featuresfinal, targetfinal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymatches.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(len(candidate_links))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymatches.sum(axis=1).value_counts().sort_index(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"potential_matches = mymatches[mymatches.sum(axis=1) < 1].reset_index() \npotential_matches['Score'] = potential_matches.loc[:,'labels']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal['features_labels'] = featuresfinal[['label']].apply(lambda x: '_'.join(x), axis=1)\ntargetfinal['target_labels'] = targetfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_label_lookup = featuresfinal[['features_labels','customer_id','label']].reset_index()\ntar_label_lookup = targetfinal[['target_labels','article','label']].reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_feat_merge  = pd.merge(potential_matches, feat_label_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_target_merge  = pd.merge(potential_matches, tar_label_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table  = pd.merge(results_feat_merge, results_target_merge,  left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['level_0_x','level_1_x','index_x','index_y','Score_x','customer_id','article','features_labels','label_y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table = final_table[cols].sort_values(by=['level_0_x'], ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change column name ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(final_table,index=[\"customer_id\",\"article\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results = final_table[['customer_id','article']]\nfinal_table_results.rename(columns={'article':'prediction'}, inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(final_table_results,index=[\"customer_id\",\"prediction\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results = pd.pivot_table(final_table_results,index=[\"customer_id\",\"prediction\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results.to_csv('submission_final_results.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.to_csv(os.path.join('/input/hm-record-linking/final_results04072022.csv'),index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\n\nfinal_table_results.to_csv('submission_final_results.csv')\ndef create_download_link(title = \"Final Result CSV file\", filename = \"submission_final_results.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename='submission_final_results.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"potential_matches.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal\n#targetfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal['features_labels'] = featuresfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targetfinal['target_labels'] = targetfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feat_label_lookup = featuresfinal[['features_labels']].reset_index()\n#tar_label_lookup = targetfinal[['target_labels']].reset_index()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#potential_matches.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_feat_merge  = pd.merge(potential_matches, feat_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_feat_merge.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_target_merge  = pd.merge(potential_matches, tar_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_target_merge.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table  = pd.merge(results_feat_merge, results_target_merge,  left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table = final_table[['level_0_x',\n# 'level_1_x','t_dat',\n#'customer_id',\n# 'price',\n# 'Active',\n# 'club_member_status',\n# 'fashion_news_frequency',\n #'product_info','jarowinkler_sim','Score_y','Features_Lookup','Target_Lookup']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def extract_first_value(row):\n #   return row.split()[0].strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table['tar_article'] = results_table['Target_Lookup'].apply(extract_first_value)\n#results_table['tar_article'] = results_table['Target_Lookup'].str.replace('[^\\w\\s]','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table['tar_article'] = results_table['tar_article'].apply(extract_first_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults = results_table[['level_0_x',\n# 'level_1_x',\n# 'customer_id',\n# 'price',\n# 'Active',\n# 'club_member_status',\n# 'fashion_news_frequency','jarowinkler_sim','Score_y','tar_article']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults['price'] = myresults['price'].astype(str)\n#myresults['Active'] = myresults['Active'].astype(str)\n#myresults['jarowinkler_sim'] = myresults['jarowinkler_sim'].astype(str)\n#myresults['Score_y'] = myresults['Score_y'].astype(str)\n#myresults['tar_article'] = myresults['tar_article'].astype(str)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults['infomation'] =  myresults['price'] +\",\"+ myresults['Active'] +\",\"+ myresults['club_member_status']+\",\"+ myresults['fashion_news_frequency']+\",\"+ myresults['jarowinkler_sim']+\",\"+ myresults['Score_y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.to_csv ('myresults.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults = myresults[['level_0_x',\n# 'level_1_x','customer_id','tar_article']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}