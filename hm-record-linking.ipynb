{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install textblob\n!pip install Distance\n!pip install zipfile36\nimport datetime\nimport seaborn as sns\nimport spacy\nfrom nltk import trigrams\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n#from keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom sklearn import metrics\n#from textblob_de import TextBlobDE as TextBlob\nfrom spacy.tokenizer import Tokenizer\nfrom spacy.lang.en import English\nimport en_core_web_lg\nnlp = spacy.blank(\"en\")\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd \nimport numpy as np \nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\nnltk.download('punkt')\nnltk.download('wordnet') \nnltk.download('omw-1.4')\nstopnow = set(stopwords.words(\"english\"))\nfrom nltk.tokenize import word_tokenize\nimport gensim\nfrom textblob import TextBlob\nfrom textblob import Word\nfrom sklearn.preprocessing import LabelEncoder\npd.set_option('display.max_columns', None)  \npd.set_option('display.max_rows', None)\nfrom string import punctuation\nfrom spacy.matcher import Matcher\nfrom spacy import displacy\nfrom gensim.models import Word2Vec\n#import en_core_web_sm\n#nlp = en_core_web_sm.load()\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import OrdinalEncoder\nimport scipy\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport time \n#import turicreate as tc \nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nfrom nltk import ngrams\nimport pandas as pd\nfrom collections import Counter\nfrom itertools import chain\nimport warnings\nwarnings.filterwarnings('ignore')\nnltk.download('averaged_perceptron_tagger')\nfrom numpy import array\n\n!pip install dedupe\n!pip install fuzzymatcher\n!pip install values\n!pip install similarity\n!pip install jarowinkler\n!pip install strsim\n!pip install pyjarowinkler\n!pip install Levenshtein\n!pip install strsimpy\n!pip install weighted-levenshtein\n!pip install recordlinkage\n!pip install keras-visualizer\n!pip install tfidf-matcher\n!pip install textdistance\n!pip install Distance\n!python3 -m pip install tabulate\n!pip install textblob\n\nfrom textblob import TextBlob\nfrom nltk.tokenize import TabTokenizer\nfrom textblob import Word\nimport tabulate\nfrom gensim.test.utils import common_texts, get_tmpfile\nfrom gensim.models import Word2Vec\nimport string\nimport values\nfrom similarity.jarowinkler import JaroWinkler\n#from similarity.levenshtein import Levenshtein\nfrom similarity.normalized_levenshtein import NormalizedLevenshtein\nfrom similarity.weighted_levenshtein import WeightedLevenshtein\nfrom similarity.weighted_levenshtein import CharacterSubstitutionInterface\nfrom similarity.damerau import Damerau\nfrom similarity.optimal_string_alignment import OptimalStringAlignment\nfrom similarity.longest_common_subsequence import LongestCommonSubsequence\nfrom similarity.metric_lcs import MetricLCS\nfrom similarity.ngram import NGram\nfrom similarity.qgram import QGram\nfrom similarity.cosine import Cosine\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom keras_visualizer import visualizer\nimport sklearn\nimport tfidf_matcher\nfrom strsimpy.jaro_winkler import JaroWinkler\nfrom strsimpy.damerau import Damerau\nfrom strsimpy.normalized_levenshtein import NormalizedLevenshtein\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport textdistance\nimport distance\nfrom gensim.models import Word2Vec\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process\nfrom difflib import SequenceMatcher\nimport sys, types, os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport matplotlib\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.util import ngrams\nfrom gensim.models import Word2Vec\nimport collections\nfrom collections import Counter\nfrom matplotlib import pyplot as plt\nstop = stopwords.words('english')\npd.options.mode.chained_assignment = None\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom spacy.matcher import Matcher\nimport spacy\nfrom spacy import displacy\nfrom gensim.models import Word2Vec\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline \nimport nltk\nimport gzip\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport heapq\nfrom wordcloud import WordCloud\nimport PIL\nimport itertools\nimport matplotlib.pyplot as plt\nfrom nltk import corpus\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect=CountVectorizer()\nimport scipy\nimport math\nimport os\nimport sklearn\nfrom itertools import islice\n\nfrom nltk import word_tokenize, pos_tag, ne_chunk\nfrom nltk import RegexpParser\nfrom nltk import Tree\nNP = \"NP: {(<V\\w+>|<NN\\w?>)+.*<NN\\w?>}\"\nchunker = RegexpParser(NP)\nfrom nltk import trigrams\nimport textdistance\n\nfrom nltk.corpus import wordnet\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\nnltk.download('punkt')\nnltk.download('wordnet')\npd.set_option('display.width', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 1000)\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv')   \ncustomer = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/customers.csv')  \ntrain = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/transactions_train.csv')\nsample = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles = articles.dropna()\ncustomer = customer.dropna()\ntrain = train.dropna()\nsample = sample.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cust_sample = sample[['customer_id']]\ntrain_sample = pd.merge(cust_sample, train,on= 'customer_id', how='left')\ntrain_sam_cust = pd.merge(train_sample, customer, on='customer_id', how='left')\ntrain_sam_cust = train_sam_cust[['t_dat','customer_id','article_id','price','Active','club_member_status','fashion_news_frequency']]\ntrain_sam_cust = train_sam_cust.sample(900000)\ntrain_sam_cust_art = pd.merge(train_sam_cust, articles, on='article_id', how='inner')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datause = train_sam_cust_art.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datause['Active'] = datause['Active'].fillna(0)\ndatause['Active'] = datause['Active'].astype(np.int64)\ndatause['fashion_news_frequency'] = datause['fashion_news_frequency'].fillna('NONE')\ndatause['club_member_status'] = datause['club_member_status'].fillna('NONE')\ndatause.product_code = datause.product_code.astype(str)\ndatause.price = datause.price.astype(str)\ndatause.article_id = datause.article_id.astype(str)\ndatause['words'] = datause['product_group_name'] +\" \"+ datause['graphical_appearance_name'] +\" \"+ datause['colour_group_name'] +\" \"+ datause['perceived_colour_value_name']+\" \"+ datause['perceived_colour_master_name'] +\" \"+ datause['department_name'] +\" \"+ datause['index_name'] +\" \"+ datause['index_group_name']+\" \"+ datause['section_name']+\" \"+ datause['garment_group_name']+\" \"+ datause['detail_desc']\ndatause.words = datause.words.astype(str)\ndatause['words'] = datause['words'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['words'] = datause['words'].str.replace('[^\\w\\s]','')\ndatause['words'] = datause['words'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopnow))\ndatause['words'] = datause['words'].str.replace('\\d+', '')\ndatause['words'] = datause['words'].str.split().apply(lambda x: ' '.join(list(set(x))))\ndatause['token_words']  = datause.apply(lambda row: nltk.word_tokenize(row['words']), axis=1)\ndatause.token_words = datause.token_words.astype(str)\ndatause['lemma_words'] = datause.token_words.apply(lemmatize_text)\n\n\n\n#datause['words'] = datause['words'].astype(str)\ndatause['product_type_name'] = datause['product_type_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['index_name'] = datause['index_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['prod_name'] = datause['prod_name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['product_type_name'] = datause['product_type_name'].str.replace('[^\\w\\s]','')\ndatause['index_name'] = datause['index_name'].str.replace('[^\\w\\s]','')\ndatause['prod_name'] = datause['prod_name'].str.replace('[^\\w\\s]','')\n\ndatause['tag'] = datause['article_id'] +\" \"+ datause['product_code'] +\" \"+ datause['product_type_name'] +\" \"+ datause['index_name']+\" \"+ datause['prod_name']+\" \"+ datause['perceived_colour_value_name']+\" \"+ datause['product_group_name']\ndatause.tag = datause.tag.astype(str)\ndatause['tag'] = datause['tag'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndatause['tag'] = datause['tag'].str.replace('[^\\w\\s]','')\ndatause['token_tag']  = datause.apply(lambda row: nltk.word_tokenize(row['tag']), axis=1)\ndatause.token_tag = datause.token_tag.astype(str)\ndatause['lemma_tag'] = datause.token_tag.apply(lemmatize_text)\n\ndatause = datause.dropna()\n\n##datause['tag'] = datause['product_code'] +\" - \"+ datause['product_type_name'] \n##datause['tag'] = datause['product_type_name'] \n##datause['tag'] = datause['tag'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n##datause = datause.dropna()\n##datause = datause.reset_index(drop=True)\n##datause['words_token'] = datause.words.apply(lambda x: word_tokenize(x))\n##datause['words_lemma'] = datause['words'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datause[['t_dat',\n 'customer_id',\n 'article_id',\n 'price',\n 'Active',\n 'club_member_status',\n 'fashion_news_frequency','token_words','lemma_words','token_tag','lemma_tag']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = dataset[['t_dat',\n 'customer_id','price','Active',\n 'club_member_status',\n 'fashion_news_frequency',\n 'lemma_tag','lemma_words']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = features[['lemma_tag']] \nfeatures = features.drop('lemma_tag',1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target['lemma_words'] = target['lemma_tag']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"features.to_csv (r'C:\\Users\\Naeemah\\Desktop\\org_features.csv', index = False, header=True)\ntarget.to_csv (r'C:\\Users\\Naeemah\\Desktop\\org_target.csv', index = False, header=True)","metadata":{}},{"cell_type":"code","source":"features['lemma_words'] = features['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target['lemma_words'] = target['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['price'] = features['price'].astype(str)\nfeatures['Active'] = features['Active'].astype(str)\n#features['product_info'] = features['product_info'].astype(str)\n#features['jarowinkler_sim'] = features['jarowinkler_sim'].astype(str)\ntarget['lemma_tag'] = target['lemma_tag'].astype(str)\ntarget['lemma_words'] = target['lemma_words'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['lemma_words'] = features['lemma_words'].str.replace(\"[\\[\\]\\\"']\", \"\")\nfeatures['lemma_words'] = features['lemma_words'].str.replace(',','')\ntarget['lemma_words'] = target['lemma_words'].str.replace(\"[\\[\\]\\\"']\", \"\")\ntarget['lemma_words'] = target['lemma_words'].str.replace(',','')\ntarget['lemma_tag'] = target['lemma_tag'].str.replace(\"[\\[\\]\\\"']\", \"\")\ntarget['lemma_tag'] = target['lemma_tag'].str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features['s_words'] = features['lemma_words'].apply(wordnet.synsets)\n#features.join(features['lemma_words'].apply(lambda word: pd.Series([w.name for w in wordnet.synsets(word)])))    \nfeatures['lemma_words_t']  = features.apply(lambda row: nltk.word_tokenize(row['lemma_words']), axis=1)    \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features['lemma_words_t'] = features['lemma_words_t'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features['lemma_words_s'] = features['lemma_words_t'].apply(wordnet.synsets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features['lemma_words_t']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def process_words(words):\n #   return (pd.DataFrame([(words, l.name())\n  #                        for words in words\n  #                        for syn in wordnet.synsets(words)\n  #                        for l in syn.lemmas()])\n   #           .drop_duplicates())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features['lemma_words_s'] = features['lemma_words_t'].apply(process_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"%%time\nimport recordlinkage\n\nindexer = recordlinkage.Index()\n# Create indexing object\nindexer = recordlinkage.SortedNeighbourhoodIndex(on='lemma_words', window=9)\n\n# Create pandas MultiIndex containing candidate links\ncandidate_links = indexer.index(features, target)\ncomp = recordlinkage.Compare()\ncomp.string('lemma_words', 'lemma_words', method='jarowinkler', label='words')\nmymatches = comp.compute(candidate_links, features, target)\nprint(mymatches)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:35.795038Z","iopub.execute_input":"2022-04-05T22:45:35.795348Z","iopub.status.idle":"2022-04-05T22:45:42.335944Z","shell.execute_reply.started":"2022-04-05T22:45:35.79531Z","shell.execute_reply":"2022-04-05T22:45:42.335188Z"}}},{"cell_type":"markdown","source":"mymatches","metadata":{}},{"cell_type":"markdown","source":"t =mymatches.sum(axis=1).value_counts().sort_index(ascending=False)\nprint(t)","metadata":{}},{"cell_type":"markdown","source":"#potential_matches = mymatches[mymatches].reset_index()\n#potential_matches['Score'] = potential_matches.loc[:,'words']\n\npotential_matches = mymatches[mymatches.sum(axis=1) < 1].reset_index()\npotential_matches['Score'] = potential_matches.loc[:,'words']\n","metadata":{}},{"cell_type":"markdown","source":"potential_matches.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:42.37937Z","iopub.execute_input":"2022-04-05T22:45:42.379641Z","iopub.status.idle":"2022-04-05T22:45:42.393797Z","shell.execute_reply.started":"2022-04-05T22:45:42.379605Z","shell.execute_reply":"2022-04-05T22:45:42.393053Z"}}},{"cell_type":"markdown","source":"potential_matches.dtypes","metadata":{}},{"cell_type":"markdown","source":"from tabulate import tabulate\nprint(tabulate(potential_matches,headers =[\"Recordid_1\",\"Recordid_2\",\"words\", \"Score\" ]))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:45:42.406558Z","iopub.execute_input":"2022-04-05T22:45:42.407034Z","iopub.status.idle":"2022-04-05T22:45:42.421611Z","shell.execute_reply.started":"2022-04-05T22:45:42.406993Z","shell.execute_reply":"2022-04-05T22:45:42.42083Z"}}},{"cell_type":"code","source":"#potential_matches['level_1']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['Features_Lookup'] = features[['lemma_words']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target['Target_Lookup'] =  target[['lemma_words']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target.to_csv ('finaltarget.csv', index = False, header=True)\n#features.to_csv ('finalfeatures.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup = features[['Features_Lookup','t_dat','customer_id','price','Active','club_member_status','fashion_news_frequency']].reset_index()\ntar_lookup = target[['Target_Lookup','lemma_words']].reset_index()\n#print(feat_lookup)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tar_lookup.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tar_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = tar_lookup[['Target_Lookup']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['target_label'] = targetfinal['Target_Lookup'].str.replace(\"[\\[\\]\\\"']\", \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['target_label'] = targetfinal['target_label'] .str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = targetfinal[['target_label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup['features_label'] = feat_lookup['Features_Lookup'].str.replace(\"[\\[\\]\\\"']\", \"\")\nfeat_lookup['features_label'] = feat_lookup['features_label'] .str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_lookup.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal = feat_lookup[['customer_id','features_label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['article'] = targetfinal['target_label'].str[:9]\ntargetfinal['target_label'] = targetfinal['target_label'].str[15:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eft_on = [\"customer_id\",\"features_label\"]\n#right_on = [\"article\",\"target_label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"matched_results = fuzzymatcher.fuzzy_left_join(featuresfinal,\n                                            targetfinal,\n                                            left_on,\n                                            right_on,\n                                            left_id_col='features_label',\n                                            right_id_col='target_label')","metadata":{}},{"cell_type":"code","source":"def get_adjectives(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"JJ\"]\n\ntargetfinal['adjectives'] = targetfinal['target_label'].apply(get_adjectives)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_verbs(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"VB\"]\n\ntargetfinal['verbs'] = targetfinal['target_label'].apply(get_verbs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nouns(text):\n    blob = TextBlob(text)\n    return [ word for (word,tag) in blob.tags if tag == \"NN\"]\n\ntargetfinal['nouns'] = targetfinal['target_label'].apply(get_nouns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targetfinal['label'] = targetfinal['adjectives'] +\" \"+ targetfinal['nouns']\ntargetfinal.adjectives = targetfinal.adjectives.astype(str)\ntargetfinal.nouns = targetfinal.nouns.astype(str)\ntargetfinal['label'] = targetfinal['adjectives'] +\" \"+ targetfinal['nouns']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal = targetfinal[['article','label']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal['label'] = targetfinal['label'].str.replace(\"[\\[\\]\\\"']\", \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal['label'] = featuresfinal['features_label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nimport recordlinkage\nindexer = recordlinkage.Index()\nindexer = recordlinkage.SortedNeighbourhoodIndex(on='label', window=9)\ncandidate_links = indexer.index(featuresfinal, targetfinal) \ncomp = recordlinkage.Compare() \ncomp.string('label', 'label', method='jarowinkler', label='labels') \nmymatches = comp.compute(candidate_links, featuresfinal, targetfinal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymatches.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(len(candidate_links))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymatches.sum(axis=1).value_counts().sort_index(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"potential_matches = mymatches[mymatches.sum(axis=1) < 1].reset_index() \npotential_matches['Score'] = potential_matches.loc[:,'labels']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featuresfinal['features_labels'] = featuresfinal[['label']].apply(lambda x: '_'.join(x), axis=1)\ntargetfinal['target_labels'] = targetfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_label_lookup = featuresfinal[['features_labels','customer_id','label']].reset_index()\ntar_label_lookup = targetfinal[['target_labels','article','label']].reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_feat_merge  = pd.merge(potential_matches, feat_label_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_target_merge  = pd.merge(potential_matches, tar_label_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table  = pd.merge(results_feat_merge, results_target_merge,  left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['level_0_x','level_1_x','index_x','index_y','Score_x','customer_id','article','features_labels','label_y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table = final_table[cols].sort_values(by=['level_0_x'], ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change column name ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(final_table,index=[\"customer_id\",\"article\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results = final_table[['customer_id','article']]\nfinal_table_results.rename(columns={'article':'prediction'}, inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(final_table_results,index=[\"customer_id\",\"prediction\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results = pd.pivot_table(final_table_results,index=[\"customer_id\",\"prediction\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_table_results.to_csv('submission_final_results.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.to_csv(os.path.join('/input/hm-record-linking/final_results04072022.csv'),index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\n\nfinal_table_results.to_csv('submission_final_results.csv')\ndef create_download_link(title = \"Final Result CSV file\", filename = \"submission_final_results.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename='submission_final_results.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"potential_matches.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal\n#targetfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#featuresfinal['features_labels'] = featuresfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targetfinal['target_labels'] = targetfinal[['label']].apply(lambda x: '_'.join(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feat_label_lookup = featuresfinal[['features_labels']].reset_index()\n#tar_label_lookup = targetfinal[['target_labels']].reset_index()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#potential_matches.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_feat_merge  = pd.merge(potential_matches, feat_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_feat_merge.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_target_merge  = pd.merge(potential_matches, tar_lookup, how='left', left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_target_merge.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table  = pd.merge(results_feat_merge, results_target_merge,  left_index=True, right_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table = final_table[['level_0_x',\n# 'level_1_x','t_dat',\n#'customer_id',\n# 'price',\n# 'Active',\n# 'club_member_status',\n# 'fashion_news_frequency',\n #'product_info','jarowinkler_sim','Score_y','Features_Lookup','Target_Lookup']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def extract_first_value(row):\n #   return row.split()[0].strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table['tar_article'] = results_table['Target_Lookup'].apply(extract_first_value)\n#results_table['tar_article'] = results_table['Target_Lookup'].str.replace('[^\\w\\s]','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table['tar_article'] = results_table['tar_article'].apply(extract_first_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results_table.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults = results_table[['level_0_x',\n# 'level_1_x',\n# 'customer_id',\n# 'price',\n# 'Active',\n# 'club_member_status',\n# 'fashion_news_frequency','jarowinkler_sim','Score_y','tar_article']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults['price'] = myresults['price'].astype(str)\n#myresults['Active'] = myresults['Active'].astype(str)\n#myresults['jarowinkler_sim'] = myresults['jarowinkler_sim'].astype(str)\n#myresults['Score_y'] = myresults['Score_y'].astype(str)\n#myresults['tar_article'] = myresults['tar_article'].astype(str)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults['infomation'] =  myresults['price'] +\",\"+ myresults['Active'] +\",\"+ myresults['club_member_status']+\",\"+ myresults['fashion_news_frequency']+\",\"+ myresults['jarowinkler_sim']+\",\"+ myresults['Score_y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.to_csv ('myresults.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults = myresults[['level_0_x',\n# 'level_1_x','customer_id','tar_article']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#myresults.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}